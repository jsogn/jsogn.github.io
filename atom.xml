<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://jsogn.github.io</id>
    <title>Jw&apos;Blogs</title>
    <updated>2020-05-09T05:23:43.990Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://jsogn.github.io"/>
    <link rel="self" href="https://jsogn.github.io/atom.xml"/>
    <logo>https://jsogn.github.io/images/avatar.png</logo>
    <icon>https://jsogn.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, Jw&apos;Blogs</rights>
    <entry>
        <title type="html"><![CDATA[vue配置跨域代理]]></title>
        <id>https://jsogn.github.io/post/vue-pei-zhi-kua-yu-dai-li/</id>
        <link href="https://jsogn.github.io/post/vue-pei-zhi-kua-yu-dai-li/">
        </link>
        <updated>2020-05-09T05:10:14.000Z</updated>
        <summary type="html"><![CDATA[<h3 id="前言">前言</h3>
<p>如果前端应用和后端 API 服务器没有运行在同一个主机上，需要在开发环境下将 API 请求代理到 API 服务器。这个问题可以通过 vue.config.js 中的 devServer.proxy 选项来配置。</p>
]]></summary>
        <content type="html"><![CDATA[<h3 id="前言">前言</h3>
<p>如果前端应用和后端 API 服务器没有运行在同一个主机上，需要在开发环境下将 API 请求代理到 API 服务器。这个问题可以通过 vue.config.js 中的 devServer.proxy 选项来配置。</p>
<!--more-->
<h3 id="vueconfigjs">vue.config.js</h3>
<p><code>vue.config.js</code> 是一个可选的配置文件，如果项目的 (和 package.json 同级的) 根目录中存在这个文件，那么它会被 @vue/cli-service 自动加载。你也可以使用 package.json 中的 vue 字段，但是注意这种写法需要你严格遵照 JSON 的格式来写。</p>
<p>这个文件应该导出一个包含了选项的对象</p>
<pre><code class="language-js">// vue.config.js
module.exports = {
  // 选项...
}
</code></pre>
<h3 id="devserverproxy">devServer.proxy</h3>
<p>devServer.proxy 可以是一个指向开发环境 API 服务器的字符串：</p>
<pre><code class="language-js">module.exports = {
  devServer: {
    proxy: 'http://localhost:4000'
  }
}
</code></pre>
<p>这会告诉开发服务器将任何未知请求 (没有匹配到静态文件的请求) 代理到http://localhost:4000。</p>
<pre><code class="language-js">module.exports = {
  devServer: {
    proxy: {
      '/api': {
        target: '&lt;url&gt;',
        ws: true,
        changeOrigin: true
        pathRewrite: {
            '^/api': ''
        }
      },
      '/foo': {
        target: '&lt;other_url&gt;'
      }
    }
  }
}
</code></pre>
<p>更多的代理控制行为，也可以使用一个 path: options 成对的对象。完整的选项可以查阅 <a href="https://github.com/chimurai/http-proxy-middleware#proxycontext-config">http-proxy-middleware</a> 。</p>
<h3 id="总结">总结</h3>
<p>以上均出自官方文档，发现很多人不知道看vue配置文档，百分之八十的问题都可以通过文档解决</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nginx访问控制]]></title>
        <id>https://jsogn.github.io/post/nginx-fang-wen-kong-zhi/</id>
        <link href="https://jsogn.github.io/post/nginx-fang-wen-kong-zhi/">
        </link>
        <updated>2020-05-09T05:09:45.000Z</updated>
        <summary type="html"><![CDATA[<h3 id="前言">前言</h3>
<p>有时，网站会被恶意入侵，可用Nginx做一些访问控制，加强一些网站安全性</p>
]]></summary>
        <content type="html"><![CDATA[<h3 id="前言">前言</h3>
<p>有时，网站会被恶意入侵，可用Nginx做一些访问控制，加强一些网站安全性</p>
<!--more-->
<h3 id="扩展名限制">扩展名限制</h3>
<p>禁止访问指定目录下的程序</p>
<pre><code class="language-conf">location ~ ^/images/.*\.(php|py)$
{
    deny all;
}

</code></pre>
<p>禁止访问指定文件名程序</p>
<pre><code class="language-conf">location ~ ^/data/(attachment|avatar).*\.(php|py)$
{
    deny all;
}
</code></pre>
<h3 id="文件或目录限制">文件或目录限制</h3>
<pre><code class="language-conf">location ~ ^/(\.user.ini|\.htaccess|\.git|\.svn|\.project|LICENSE|README.md) {
    return 404;
}
</code></pre>
<p>排除某个目录不受限制</p>
<pre><code class="language-conf">location ~ \.well-known{
    allow all;
}
</code></pre>
<p>禁止访问单个目录</p>
<pre><code class="language-conf">location ~ ^/static {
    deny all;
}
</code></pre>
<p>禁止访问多个目录，并返回指定状态码</p>
<pre><code class="language-conf">location ~ ^/(static|js) {
    return 404;
}
</code></pre>
<h3 id="限制ip访问">限制IP访问</h3>
<p>禁止目录访问，但允许某IP访问</p>
<pre><code class="language-conf">location ~ ^/mysql_loging/ {
    allow 192.168.0.4;
    deny all;
}
</code></pre>
<p>限制IP或IP段访问</p>
<pre><code class="language-conf">location / {
    deny 192.168.0.4;
    allow 192.168.1.0/16;
    allow 10.0.0.0/24;
    deny all;
}
</code></pre>
<p>nginx做反向代理的时候也可以限制客户端IP</p>
<pre><code class="language-conf">if ( $remoteaddr = 10.0.0.7 ) {
    return 403;
}

if ( $remoteaddr = 218.247.17.130 ) {
    set $allow_access_root 'ture';
}
</code></pre>
<p>禁止某ip段访问并向浏览器输出一段文字（若有乱码,请在server中添加：charset utf-8;）</p>
<pre><code class="language-conf">if ($remote_addr ~* ^211\.149\.(.*?)\.(.*?)$){
return 404 &quot;黑名单用户，拒绝访问&quot;;
}
</code></pre>
<h3 id="禁止非法域名解析访问">禁止非法域名解析访问</h3>
<p>让使用IP访问网站的用户，或恶意接卸域名的用户，收到501错误</p>
<pre><code class="language-conf">server {
    listen 80 default_server;
    server_name _;
    return 501;
}
</code></pre>
<p>通过301跳转主页</p>
<pre><code class="language-conf">server {
    listen 80 default_server;
    server_name _;
    rewrite ^(.*) http://blog.dns.com/$1 permanent;
}
</code></pre>
<p>发现某域名恶意解析到公司的服务器IP，在server标签里添加以下代码即可，若有多个server要多处添加</p>
<pre><code class="language-conf">if ($host !~ ^www/.tag/.com$) {
    rewrite ^(.*) http://blog.mydns.vip$1 permanent;
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[平滑重启php-fpm]]></title>
        <id>https://jsogn.github.io/post/ping-hua-chong-qi-php-fpm/</id>
        <link href="https://jsogn.github.io/post/ping-hua-chong-qi-php-fpm/">
        </link>
        <updated>2020-05-09T05:09:19.000Z</updated>
        <summary type="html"><![CDATA[<h3 id="前言">前言</h3>
<p>php-fpm 会对下面几个信号作（自己的）处理</p>
<ul>
<li>SIGINT, SIGTERM: immediate termination</li>
<li>SIGQUIT: graceful stop</li>
<li>SIGUSR1: re-open log file</li>
<li>SIGUSR2: graceful reload of all workers + reload of fpm conf/binary</li>
</ul>
]]></summary>
        <content type="html"><![CDATA[<h3 id="前言">前言</h3>
<p>php-fpm 会对下面几个信号作（自己的）处理</p>
<ul>
<li>SIGINT, SIGTERM: immediate termination</li>
<li>SIGQUIT: graceful stop</li>
<li>SIGUSR1: re-open log file</li>
<li>SIGUSR2: graceful reload of all workers + reload of fpm conf/binary</li>
</ul>
<!--more-->
<h3 id="理解">理解</h3>
<p>master进程可以理解以下信号</p>
<ul>
<li>INT （2）, TERM（15） 立刻终止</li>
<li>QUIT （3） 平滑终止</li>
<li>USR1 重新打开日志文件</li>
<li>USR2 平滑重载所有worker进程并重新载入配置和二进制模块</li>
</ul>
<h4 id="查看进程数">查看进程数</h4>
<pre><code class="language-bash">ps aux | grep -c php-fpm
</code></pre>
<h4 id="查看master进程号">查看master进程号</h4>
<pre><code class="language-bash">ps aux|grep 'php-fpm: master' | awk '{print $2}'
</code></pre>
<h4 id="平滑重启">平滑重启</h4>
<pre><code class="language-bash">kill -USR2 `cat /usr/local/php/var/run/php-fpm.pid`
</code></pre>
<p>OR</p>
<pre><code class="language-bash">kill -USR2 [pid]
</code></pre>
<h3 id="脚本实现">脚本实现</h3>
<h4 id="centos脚本实现">centos脚本实现</h4>
<pre><code class="language-bash">#!/bin/bash
echo &quot;php-fpm is reloading....&quot;
PID=`ps aux | grep php-fpm | grep &quot;master&quot; |awk '{print $2}'`

[ $PID ] &amp;&amp; kill -USR2 $PID || echo &quot;php-fpm is useing(pid=$PID)&quot;
echo &quot;reload done!&quot;
echo &quot;php-fpm is reload...&quot;
echo &quot;reload done!&quot;
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis性能优化整理]]></title>
        <id>https://jsogn.github.io/post/redis-xing-neng-you-hua-zheng-li/</id>
        <link href="https://jsogn.github.io/post/redis-xing-neng-you-hua-zheng-li/">
        </link>
        <updated>2020-05-09T05:08:54.000Z</updated>
        <summary type="html"><![CDATA[<h3 id="前言">前言</h3>
<p>Redis 是基于单线程模型实现的，也就是 Redis 是使用一个线程来处理所有的客户端请求的，尽管 Redis 使用了非阻塞式 IO，并且对各种命令都做了优化（大部分命令操作时间复杂度都是 O(1)），但由于 Redis 是单线程执行的特点，因此它对性能的要求更加苛刻。</p>
]]></summary>
        <content type="html"><![CDATA[<h3 id="前言">前言</h3>
<p>Redis 是基于单线程模型实现的，也就是 Redis 是使用一个线程来处理所有的客户端请求的，尽管 Redis 使用了非阻塞式 IO，并且对各种命令都做了优化（大部分命令操作时间复杂度都是 O(1)），但由于 Redis 是单线程执行的特点，因此它对性能的要求更加苛刻。</p>
<!--more-->
<h3 id="开启-lazy-free-特性">开启 lazy free 特性</h3>
<p>lazy free 特性是 Redis 4.0 新增的一个非常使用的功能，它可以理解为惰性删除或延迟删除。意思是在删除的时候提供异步延时释放键值的功能，把键值释放操作放在 BIO(Background I/O) 单独的子线程处理中，以减少删除删除对 Redis 主线程的阻塞，可以有效地避免删除 big key 时带来的性能和可用性问题。</p>
<pre><code class="language-xml">lazyfree-lazy-eviction no
lazyfree-lazy-expire no
lazyfree-lazy-server-del no
slave-lazy-flush no
</code></pre>
<ul>
<li>lazyfree-lazy-eviction：表示当 Redis 运行内存超过 maxmeory 时，是否开启 lazy free 机制删除；</li>
<li>lazyfree-lazy-expire：表示设置了过期时间的键值，当过期之后是否开启 lazy free 机制删除；</li>
<li>lazyfree-lazy-server-del：有些指令在处理已存在的键时，会带有一个隐式的 del 键的操作，比如 rename 命令，当目标键已存在，Redis 会先删除目标键，如果这些目标键是一个 big key，就会造成阻塞删除的问题，此配置表示在这种场景中是否开启 lazy free 机制删除；</li>
<li>slave-lazy-flush：针对 slave(从节点) 进行全量数据同步，slave 在加载 master 的 RDB 文件前，会运行 flushall 来清理自己的数据，它表示此时是否开启 lazy free 机制删除。</li>
</ul>
<p>开启其中的 lazyfree-lazy-eviction、lazyfree-lazy-expire、lazyfree-lazy-server-del 等配置，这样就可以有效的提高主线程的执行效率。</p>
<h3 id="使用-slowlog-优化耗时命令">使用 slowlog 优化耗时命令</h3>
<p>可以使用 slowlog 功能找出最耗时的 Redis 命令进行相关的优化，以提升 Redis 的运行速度，慢查询有两个重要的配置项：</p>
<ul>
<li>slowlog-log-slower-than ：用于设置慢查询的评定时间，也就是说超过此配置项的命令，将会被当成慢操作记录在慢查询日志中，它执行单位是微秒 (1 秒等于 1000000 微秒)；</li>
<li>slowlog-max-len ：用来配置慢查询日志的最大记录数。</li>
</ul>
<p>可以根据实际的业务情况进行相应的配置，其中慢日志是按照插入的顺序倒序存入慢查询日志中，可以使用 slowlog get n 来获取相关的慢查询日志，再找到这些慢查询对应的业务进行相关的优化。</p>
<h3 id="使用-pipeline-批量操作数据">使用 Pipeline 批量操作数据</h3>
<p>Pipeline (管道技术) 是客户端提供的一种批处理技术，用于一次处理多个 Redis 命令，从而提高整个交互的性能。</p>
<h3 id="避免大量数据同时失效">避免大量数据同时失效</h3>
<p>Redis 过期键值删除使用的是贪心策略，它每秒会进行 10 次过期扫描，此配置可在 redis.conf 进行配置，默认值是 hz 10，Redis 会随机抽取 20 个值，删除这 20 个键中过期的键，如果过期 key 的比例超过 25% ，重复执行此流程。</p>
<p>如果在大型系统中有大量缓存在同一时间同时过期，那么会导致 Redis 循环多次持续扫描删除过期字典，直到过期字典中过期键值被删除的比较稀疏为止，而在整个执行过程会导致 Redis 的读写出现明显的卡顿，卡顿的另一种原因是内存管理器需要频繁回收内存页，因此也会消耗一定的 CPU。<br>
为了避免这种卡顿现象的产生，我们需要预防大量的缓存在同一时刻一起过期，就简单的解决方案就是在过期时间的基础上添加一个指定范围的随机数。</p>
<h3 id="连接池">连接池</h3>
<p>尽量使用 Redis 连接池，而不是频繁创建销毁 Redis 连接，这样就可以减少网络传输次数和减少了非必要调用指令。</p>
<h3 id="限制-redis-内存大小">限制 Redis 内存大小</h3>
<p>在 64 位操作系统中 Redis 的内存大小是没有限制的，也就是配置项 <code>maxmemory &lt;bytes&gt;</code> 是被注释掉的，这样就会导致在物理内存不足时，使用 swap 空间既交换空间，而当操心系统将 Redis 所用的内存分页移至 swap 空间时，将会阻塞 Redis 进程，导致 Redis 出现延迟，从而影响 Redis 的整体性能。</p>
<p>因此需要限制 Redis 的内存大小为一个固定的值，当 Redis 的运行到达此值时会触发内存淘汰策略，内存淘汰策略在 Redis 4.0 之后有 8 种：</p>
<ul>
<li>noeviction：不淘汰任何数据，当内存不足时，新增操作会报错，Redis 默认内存淘汰策略；</li>
<li>allkeys-lru：淘汰整个键值中最久未使用的键值；</li>
<li>allkeys-random：随机淘汰任意键值;</li>
<li>volatile-lru：淘汰所有设置了过期时间的键值中最久未使用的键值；</li>
<li>volatile-random：随机淘汰设置了过期时间的任意键值；</li>
<li>volatile-ttl：优先淘汰更早过期的键值。</li>
</ul>
<p>在 Redis 4.0 版本中又新增了 2 种淘汰策略：</p>
<ul>
<li>volatile-lfu：淘汰所有设置了过期时间的键值中，最少使用的键值；</li>
<li>allkeys-lfu：淘汰整个键值中最少使用的键值。</li>
</ul>
<p>其中 allkeys-xxx 表示从所有的键值中淘汰数据，而 volatile-xxx 表示从设置了过期键的键值中淘汰数据。<br>
可以根据实际的业务情况进行设置，默认的淘汰策略不淘汰任何数据，在新增时会报错。</p>
<h3 id="混合持久化">混合持久化</h3>
<p>Redis 的持久化策略是将内存数据复制到硬盘上，这样才可以进行容灾恢复或者数据迁移，但维护此持久化的功能，需要很大的性能开销。<br>
在 Redis 4.0 之后，Redis 有 3 种持久化的方式：</p>
<ul>
<li>RDB（Redis DataBase，快照方式）将某一个时刻的内存数据，以二进制的方式写入磁盘；</li>
<li>AOF（Append Only File，文件追加方式），记录所有的操作命令，并以文本的形式追加到文件中；</li>
<li>混合持久化方式，Redis 4.0 之后新增的方式，混合持久化是结合了 RDB 和 AOF 的优点，在写入的时候，先把当前的数据以 RDB 的形式写入文件的开头，再将后续的操作命令以 AOF 的格式存入文件，这样既能保证 Redis 重启时的速度，又能减低数据丢失的风险。</li>
</ul>
<p>RDB 和 AOF 持久化各有利弊，RDB 可能会导致一定时间内的数据丢失，而 AOF 由于文件较大则会影响 Redis 的启动速度，为了能同时拥有 RDB 和 AOF 的优点，Redis 4.0 之后新增了混合持久化的方式，因此我们在必须要进行持久化操作时，应该选择混合持久化的方式。<br>
查询是否开启混合持久化可以使用 <code>config get aof-use-rdb-preamble</code> 命令</p>
<h3 id="禁用-thp-特性">禁用 THP 特性</h3>
<p>Linux kernel 在 2.6.38 内核增加了 Transparent Huge Pages (THP) 特性 ，支持大内存页 2MB 分配，默认开启。<br>
当开启了 THP 时，fork 的速度会变慢，fork 之后每个内存页从原来 4KB 变为 2MB，会大幅增加重写期间父进程内存消耗。同时每次写命令引起的复制内存页单位放大了 512 倍，会拖慢写操作的执行时间，导致大量写操作慢查询。例如简单的 incr 命令也会出现在慢查询中，因此 Redis 建议将此特性进行禁用，禁用方法如下：</p>
<pre><code class="language-bash">echo never &gt;  /sys/kernel/mm/transparent_hugepage/enabled
</code></pre>
<p>为了使机器重启后 THP 配置依然生效，可以在 <code>/etc/rc.local</code> 中追加 <code>echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</code>。</p>
<h3 id="使用分布式架构">使用分布式架构</h3>
<p>Redis 分布式架构有三个重要的手段：</p>
<ul>
<li>主从同步</li>
<li>哨兵模式</li>
<li>Redis Cluster 集群</li>
</ul>
<p>使用主从同步功能我们可以把写入放到主库上执行，把读功能转移到从服务上，因此就可以在单位时间内处理更多的请求，从而提升的 Redis 整体的运行速度。</p>
<p>而哨兵模式是对于主从功能的升级，但当主节点奔溃之后，无需人工干预就能自动恢复 Redis 的正常使用。</p>
<p>Redis Cluster 是 Redis 3.0 正式推出的，Redis 集群是通过将数据库分散存储到多个节点上来平衡各个节点的负载压力。</p>
<p>Redis Cluster 采用虚拟哈希槽分区，所有的键根据哈希函数映射到 0 ~ 16383 整数槽内，计算公式：slot = CRC16(key) &amp; 16383，每一个节点负责维护一部分槽以及槽所映射的键值数据。这样 Redis 就可以把读写压力从一台服务器，分散给多台服务器了，因此性能会有很大的提升。</p>
<p>在这三个功能中，只需要使用一个就行了，毫无疑问 Redis Cluster 应该是首选的实现方案，它可以把读写压力自动的分担给更多的服务器，并且拥有自动容灾的能力。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[PAC规则配置]]></title>
        <id>https://jsogn.github.io/post/pac-gui-ze-pei-zhi/</id>
        <link href="https://jsogn.github.io/post/pac-gui-ze-pei-zhi/">
        </link>
        <updated>2020-05-09T05:08:32.000Z</updated>
        <summary type="html"><![CDATA[<h3 id="前言">前言</h3>
<p>访问github加载过慢，下载项目奇慢无比，开启全局后可以秒下，反应过来github.com默认没有走代理，整理了一些PAC规则的基本配置</p>
]]></summary>
        <content type="html"><![CDATA[<h3 id="前言">前言</h3>
<p>访问github加载过慢，下载项目奇慢无比，开启全局后可以秒下，反应过来github.com默认没有走代理，整理了一些PAC规则的基本配置</p>
<!--more-->
<h3 id="基本规则">基本规则</h3>
<ul>
<li>
<p>通配符支持，如 <code>*.example.com/*</code> 实际书写时可省略 如： <code>.example.com/</code> 意即 <code>.example.com/*</code></p>
</li>
<li>
<p>正则表达式支持，以 <code>\</code> 开始和结束， 如： <code>\[\w]+:\/\/example.com\</code></p>
</li>
<li>
<p>例外规则 <code>@@</code>，如 <code>@@*.example.com/*</code> 满足 <code>@@</code> 后规则的地址不使用代理</p>
</li>
<li>
<p>匹配地址开始和结尾 <code>|</code>，如： <code>|http://example.com</code>、<code>example.com|</code> 分别表示以 <code>http://example.com</code> 开始和以 <code>example.com</code> 结束的地址</p>
</li>
<li>
<p>|| 标记，如： <code>||example.com</code> 则 <code>http://example.com</code> 、<code>https://example.com</code> 、<code>ftp://example.com</code> 等地址均满足条件，只用于匹配地址开头</p>
</li>
<li>
<p>注释 <code>!</code> 如： <code>! Comment</code></p>
</li>
<li>
<p>分隔符 <code>^</code>，表示除了字母、数字或者 <code>_ - . %</code> 之外的任何字符如： <code>http://example.com^</code> ，<code>http://example.com/</code> 和 <code>http://example.com:8000/</code> 均满足条件，而 <code>http://example.com.ar/</code> 不满足条件</p>
</li>
</ul>
<h3 id="自定义规则">自定义规则</h3>
<pre><code class="language-conf">! Put user rules line by line in this file.

! See https://adblockplus.org/en/filter-cheatsheet

@@||localhost

||github.com

</code></pre>
<p>一行只能有一条代理规则，生效后被配置的域名及其子域名都会经过代理访问</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[设置CentOS服务器IP地址]]></title>
        <id>https://jsogn.github.io/post/she-zhi-centos-fu-wu-qi-ip-di-zhi/</id>
        <link href="https://jsogn.github.io/post/she-zhi-centos-fu-wu-qi-ip-di-zhi/">
        </link>
        <updated>2020-05-09T05:08:01.000Z</updated>
        <summary type="html"><![CDATA[<h3 id="前言">前言</h3>
<p>如何在CentOS服务器中配置网络IP地址</p>
]]></summary>
        <content type="html"><![CDATA[<h3 id="前言">前言</h3>
<p>如何在CentOS服务器中配置网络IP地址</p>
<!--more-->
<h3 id="设置ip地址">设置IP地址</h3>
<pre><code class="language-shell">cd /etc/sysconfig/network-scripts/
</code></pre>
<p>查看配置信息</p>
<pre><code class="language-shell">ifconfig
</code></pre>
<p>编辑网卡配置</p>
<pre><code class="language-shell">vim ifcfg-eno1
</code></pre>
<p>编辑信息，建议 <code>ONBOOT=yes</code>，以后开机就会自动联网：</p>
<pre><code class="language-ini">TYPE=&quot;Ethernet&quot;
BOOTPROTO=&quot;none&quot;
DEFROUTE=&quot;yes&quot;
IPV4_FAILURE_FATAL=&quot;no&quot;
IPV6INIT=&quot;yes&quot;
IPV6_AUTOCONF=&quot;yes&quot;
IPV6_DEFROUTE=&quot;yes&quot;
IPV6_FAILURE_FATAL=&quot;no&quot;
NAME=&quot;eno1&quot;
UUID=&quot;c63850e5-4c25-46c7-a030-574fcf824ad5&quot;
DEVICE=&quot;eno1&quot; #设备别名
ONBOOT=&quot;yes&quot;
IPADDR1=202.95.22.222 #从IP地址1
PREFIX1=&quot;25&quot;
IPADDR2=202.95.22.233 #从IP地址2
PREFIX2=&quot;25&quot;
DNS1=&quot;8.8.8.8&quot; #DNS服务器
IPADDR=202.95.22.212  #设置主IP地址
PREFIX=25
GATEWAY=202.95.8.129 #网关
IPV6_PEERDNS=yes
IPV6_PEERROUTES=yes
IPV6_PRIVACY=no
</code></pre>
<h3 id="重启网络配置">重启网络配置</h3>
<pre><code class="language-shell">systemctl restart network
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[阿里云RDS与ECS服务器数据库做主从]]></title>
        <id>https://jsogn.github.io/post/a-li-yun-rds-yu-ecs-fu-wu-qi-shu-ju-ku-zuo-zhu-cong/</id>
        <link href="https://jsogn.github.io/post/a-li-yun-rds-yu-ecs-fu-wu-qi-shu-ju-ku-zuo-zhu-cong/">
        </link>
        <updated>2020-05-09T05:07:29.000Z</updated>
        <summary type="html"><![CDATA[<h3 id="前言">前言</h3>
<p>实现RDS for mysql与线下ECS上自建数据库数据实时同步，阿里云官方推荐使用DTS方式进行。原因有两个：</p>
<ul>
<li>
<p>mysql-bin正常情况下,RDS在本地只保存18个小时</p>
</li>
<li>
<p>当RDS实例切换时，会影响自建ECS数据同步(这个经过测试可以排除)</p>
</li>
</ul>
<p>考虑到使用DTS工具会产生不少的费用(长期使用)，另一方面，在数据库中一个地区对应一个库，后续业务无法事先规划好库名，此时如果使用dts可能需要购买多个通道，进行配置，比较费时费力且费钱。基于这两个原因的考虑，决定使用搭建主从复制方式来实现数据同步</p>
]]></summary>
        <content type="html"><![CDATA[<h3 id="前言">前言</h3>
<p>实现RDS for mysql与线下ECS上自建数据库数据实时同步，阿里云官方推荐使用DTS方式进行。原因有两个：</p>
<ul>
<li>
<p>mysql-bin正常情况下,RDS在本地只保存18个小时</p>
</li>
<li>
<p>当RDS实例切换时，会影响自建ECS数据同步(这个经过测试可以排除)</p>
</li>
</ul>
<p>考虑到使用DTS工具会产生不少的费用(长期使用)，另一方面，在数据库中一个地区对应一个库，后续业务无法事先规划好库名，此时如果使用dts可能需要购买多个通道，进行配置，比较费时费力且费钱。基于这两个原因的考虑，决定使用搭建主从复制方式来实现数据同步</p>
<!--more-->
<h3 id="基础概念">基础概念</h3>
<p>传统的MYSQL主从就是主库每做一个操作会在binlog上做一个position，每做一个event就在binlog做一个起始编号、一个终止编号。然后主库把binlog传递给从库，然后从库根据这个binlog的pos值就按照顺序做一样的操作，达到两个数据库保持一致的目的。</p>
<p>GTID不用这个position的方式，而是用了全局事物标识，这个标识的格式是<code>source_id:transaction_id</code>，如<code>3E11FA47-71CA-11E1-9E33-C80AA9429562:23</code></p>
<ul>
<li>
<p>source_id即是server_uuid，在第一次启动时生成(函数 generate_server_uuid)，并持久化到DATADIR/auto.cnf文件里</p>
</li>
<li>
<p>transaction_id是顺序化的序列号(sequence number)，在每台 MySQL 服务器上都是从 1 开始自增长的序列，是事务的唯一标识</p>
</li>
</ul>
<p>它的主从过程是这样的：主库更新数据时，会在事务前产生GTID，连通sql记录到binlog日志中。从库的i/o线程将变更的binlog写入到relay log中，读取值是根据gitd_next变量，告诉从库下一个执行哪个GTID。从库的sql线程从relay log中获取GTID，然后对比从库的的binlog是否有记录。如果有记录，说明该GTID的事务已经执行，从库会忽略。如果没有记录，从库就会从relay log中执行该GTID的事务，并记录到从库binlog。在解析过程中会判断是否有主键，如果没有就用二级索引，如果没有二级索引就用全部扫描。</p>
<p>也就是说，无论是级联情况，还是一主多从情况，都可以通过GTID自动找点儿，而无需像之前那样通过binlog和binlog_position找点儿了</p>
<h3 id="rds数据库配置">RDS数据库配置</h3>
<ul>
<li>配置从实例读取数据使用的只读账号和授权数据库</li>
<li>将ECS的从实例的 IP 地址加入主实例的 IP 白名单中</li>
<li>登录主实例</li>
</ul>
<h4 id="查询-server-id">查询 server-id</h4>
<pre><code class="language-mysql">mysql&gt; show variables like 'server_id';
</code></pre>
<h4 id="查询-gtid">查询 GTID</h4>
<pre><code class="language-mysql">mysql&gt; show global variables like 'gtid_purged';
</code></pre>
<h3 id="ecs数据库配置">ECS数据库配置</h3>
<h4 id="mysql文件配置">mysql文件配置</h4>
<pre><code class="language-conf">server-id = 1001 #不可与RDS主库id相同
port = 3306
replicate-do-db = masterdb #需要同步的数据库

binlog_format = row #日志文件格式
log-bin = mysql-bin
log-bin-index = mysql-bin.index
relay-log = relay-log
relay_log_index = relay-log.index
slave-skip-errors = all
</code></pre>
<h4 id="gtid配置">GTID配置</h4>
<pre><code class="language-conf">gtid_mode = on
enforce_gtid_consistency = on
log-slave-updates = 1

sql_mode = NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES
</code></pre>
<h4 id="从库配置">从库配置</h4>
<pre><code class="language-mysql">mysql&gt; stop slave;
mysql&gt; set global gtid_purged = '533ac4e6-9565-11e8-abb5-7cd30abca02e:1-3099396';
</code></pre>
<blockquote>
<p>注意：设置gtid_purged值时，gtid_executed值必须为空否则报错，该值清空的方法就是reset  master命令</p>
</blockquote>
<pre><code class="language-mysql">mysql&gt;reset master;
</code></pre>
<h4 id="执行同步">执行同步</h4>
<pre><code class="language-mysql">CHANGE MASTER TO
MASTER_HOST='xxxxxxx.mysql.rds.aliyuncs.com',
MASTER_PORT=3306,
MASTER_USER='username',
MASTER_PASSWORD='password',
master_auto_position=1;

mysql&gt;start slave;
</code></pre>
<h4 id="查看从库状态">查看从库状态</h4>
<pre><code class="language-mysql">mysql&gt;show slave status\G;
</code></pre>
<p>两个yes表示成功</p>
<pre><code class="language-mysql">  Slave_IO_Running: Yes
  Slave_SQL_Running: Yes
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis由于连接过多导致的异常]]></title>
        <id>https://jsogn.github.io/post/redis-you-yu-lian-jie-guo-duo-dao-zhi-de-yi-chang/</id>
        <link href="https://jsogn.github.io/post/redis-you-yu-lian-jie-guo-duo-dao-zhi-de-yi-chang/">
        </link>
        <updated>2020-05-09T05:06:42.000Z</updated>
        <summary type="html"><![CDATA[<h3 id="前言">前言</h3>
<p>近期服务器在高峰的时候经常报错，日志记录为：</p>
<pre><code>Redis-&gt;connect('127.0.0.1', 6379)
#1 {main}
  thrown in /wwwroot/test.php on line 9
[13-Jun-2019 11:07:47 PRC] PHP Fatal error:  Uncaught RedisException: Cannot assign requested address in /wwwroot/test.php:9
</code></pre>
]]></summary>
        <content type="html"><![CDATA[<h3 id="前言">前言</h3>
<p>近期服务器在高峰的时候经常报错，日志记录为：</p>
<pre><code>Redis-&gt;connect('127.0.0.1', 6379)
#1 {main}
  thrown in /wwwroot/test.php on line 9
[13-Jun-2019 11:07:47 PRC] PHP Fatal error:  Uncaught RedisException: Cannot assign requested address in /wwwroot/test.php:9
</code></pre>
<!--more-->
<h3 id="解决方法">解决方法</h3>
<h4 id="方法一">方法一</h4>
<p>执行命令修改如下 2 个内核参数</p>
<pre><code class="language-sh">sysctl -w net.ipv4.tcp_timestamps=1 开启对于 TCP 时间戳的支持, 若该项设置为 0，则下面一项设置不起作用

sysctl -w net.ipv4.tcp_tw_recycle=1 表示开启 TCP 连接中 TIME-WAIT sockets 的快速回收

Redis 错误 ：Cannot assign request

Could not connect to Redis at 127.0.0.1:6379: connect: Cannot assign request
</code></pre>
<p>经查官方 Wiki 是系统网络配置问题已经解决：</p>
<pre><code class="language-sh">echo 1 &gt; /proc/sys/net/ipv4/tcp_tw_reuse
</code></pre>
<p>以上需要 root 权限对网络进行配置。</p>
<h4 id="方法二">方法二</h4>
<p>通过调整内核参数解决，<code>vim /etc/sysctl.conf</code>，加入</p>
<pre><code>net.ipv4.tcp_syncookies = 1 #表示开启 SYN Cookies。当出现 SYN 等待队列溢出时，启用 cookies 来处理，可防范少量 SYN 攻击，默认为 0，表示关闭；

net.ipv4.tcp_tw_reuse = 1 #表示开启重用。允许将 TIME-WAIT sockets 重新用于新的 TCP 连接，默认为 0，表示关闭，释放 TIME_WAIT 端口给新连接使用；

net.ipv4.tcp_tw_recycle = 1 #表示开启 TCP 连接中 TIME-WAIT sockets 的快速回收资源，默认为 0，表示关闭。

net.ipv4.tcp_fin_timeout = 30 #修改系統默认的 TIMEOUT 时间，调低端口释放后的等待时间，默认为 60s，修改为 15~30s

net.ipv4.tcp_max_tw_buckets = 10000# 通过设置它，系统会将多余的 TIME_WAIT 删除掉，此时系统日志里可能会显示：『TCP: time wait bucket table overflow』，多数情况下不用在意这些信息。
</code></pre>
<p>然后执行 <code>/sbin/sysctl -p</code> 让参数生效。</p>
<p>以上都可以通过命令（sysctl -w）方式操作，如：<code>sysctl -w net.ipv4.tcp_fin_timeout=30</code> ，只适合临时修改参数。</p>
<h3 id="tcp-网络参数优化">TCP 网络参数优化</h3>
<pre><code class="language-sh">echo &quot;1024 65535&quot; &gt; /proc/sys/net/ipv4/ip_local_port_range 设置向外连接可用端口范围 表示可以使用的端口为 65535-1024 个（0~1024 为受保护的)

echo 1 &gt; /proc/sys/net/ipv4/tcp_tw_reuse 设置 time_wait 连接重用 默认 0

echo 1 &gt; /proc/sys/net/ipv4/tcp_tw_recycle 设置快速回收 time_wait 连接 默认 0

echo 180000 &gt; /proc/sys/net/ipv4/tcp_max_tw_buckets 设置最大 time_wait 连接长度 默认 262144

echo 1 &gt; /proc/sys/net/ipv4/tcp_timestamps  设置是否启用比超时重发更精确的方法来启用对 RTT 的计算 默认 0

echo 1 &gt; /proc/sys/net/ipv4/tcp_window_scaling 设置 TCP/IP 会话的滑动窗口大小是否可变 默认 1

echo 20000 &gt; /proc/sys/net/ipv4/tcp_max_syn_backlog 设置最大处于等待客户端没有应答的连接数 默认 2048

echo 15 &gt; /proc/sys/net/ipv4/tcp_fin_timeout  设置 FIN-WAIT 状态等待回收时间 默认 60

echo &quot;4096 87380 16777216&quot; &gt; /proc/sys/net/ipv4/tcp_rmem  设置最大 TCP 数据发送缓冲大小，分别为最小、默认和最大值  默认 4096    87380   4194304

echo &quot;4096 65536 16777216&quot; &gt; /proc/sys/net/ipv4/tcp_wmem 设置最大 TCP 数据 接受缓冲大小，分别为最小、默认和最大值 　默认 4096    87380   4194304

echo 10000 &gt; /proc/sys/net/core/somaxconn  设置每一个处于监听状态的端口的监听队列的长度 默认 128

echo 10000 &gt; /proc/sys/net/core/netdev_max_backlog 设置最大等待 cpu 处理的包的数目 默认 1000

echo 16777216 &gt; /proc/sys/net/core/rmem_max 设置最大的系统套接字数据接受缓冲大小 默认 124928

echo 262144 &gt; /proc/sys/net/core/rmem_default  设置默认的系统套接字数据接受缓冲大小 默认 124928

echo 16777216 &gt; /proc/sys/net/core/wmem_max  设置最大的系统套接字数据发送缓冲大小 默认 124928

echo 262144 &gt; /proc/sys/net/core/wmem_default  设置默认的系统套接字数据发送缓冲大小 默认 124928

echo 2000000 &gt; /proc/sys/fs/file-max 设置最大打开文件数 默认 385583
</code></pre>
<p>结合 ab 命令来压测机器优化网络，设置完记得保存</p>
<h3 id="优化-redis-命令">优化 Redis 命令</h3>
<p>设置内存分配方式：</p>
<pre><code>echo 1 &gt; /proc/sys/vm/overcommit_memory
</code></pre>
<p>0 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。</p>
<p>1 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。</p>
<p>2 表示内核允许分配超过所有物理内存和交换空间总和的内存</p>
<p>关闭 THP：</p>
<pre><code>cho never &gt; /sys/kernel/mm/transparent_hugepage/enabled
</code></pre>
<p>尽管 THP 的本意是为提升性能，但某些数据库厂商还是建议直接关闭 THP(比如说 Oracle、MongoDB 等)，否则可能导致性能下降，内存锁，甚至系统重启等问题。</p>
<pre><code>echo 1024 &gt;/proc/sys/net/core/somaxconn
</code></pre>
<p>限制了接收新 TCP 连接侦听队列的大小。对于一个经常处理新连接的高负载 web 服务环境来说，默认的 128 太小了。大多数环境这个值建议增加到 1024 或者更多。 服务进程会自己限制侦听队列的大小 (例如 sendmail(8) 或者 Apache)，常常在它们的配置文件中有设置队列大小的选项。大的侦听队列对防止拒绝服务 DoS 攻击也会有所帮助。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[网站访问日志的日常操作]]></title>
        <id>https://jsogn.github.io/post/wang-zhan-fang-wen-ri-zhi-de-ri-chang-cao-zuo/</id>
        <link href="https://jsogn.github.io/post/wang-zhan-fang-wen-ri-zhi-de-ri-chang-cao-zuo/">
        </link>
        <updated>2020-05-09T05:06:03.000Z</updated>
        <summary type="html"><![CDATA[<h3 id="前言">前言</h3>
<p>日常工作中，网站如果遇到异常情况，经常需要查看访问日志来查找问题，由于日志文件庞大查找起来很不放便，所以需要进行一些过滤处理</p>
]]></summary>
        <content type="html"><![CDATA[<h3 id="前言">前言</h3>
<p>日常工作中，网站如果遇到异常情况，经常需要查看访问日志来查找问题，由于日志文件庞大查找起来很不放便，所以需要进行一些过滤处理</p>
<!--more-->
<h3 id="筛选出可疑ip的访问日志">筛选出可疑IP的访问日志</h3>
<pre><code>cat example.log | grep '127.0.0.1' &gt; 127.0.0.1.log
</code></pre>
<h3 id="筛选出日志的某一列数据">筛选出日志的某一列数据</h3>
<pre><code>awk -F &quot;,&quot; '{print $2&quot; &quot;$3&quot;}' example.log
</code></pre>
<h3 id="根据某列数据进行去重">根据某列数据进行去重</h3>
<pre><code>awk -F &quot;,&quot;  '!a[$2,$3]++'  example.log
</code></pre>
<h3 id="去除重复行">去除重复行</h3>
<pre><code>sort example.log | uniq
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Vue 中 axios 的封装]]></title>
        <id>https://jsogn.github.io/post/vue-zhong-axios-de-feng-zhuang/</id>
        <link href="https://jsogn.github.io/post/vue-zhong-axios-de-feng-zhuang/">
        </link>
        <updated>2020-05-09T05:05:37.000Z</updated>
        <summary type="html"><![CDATA[<h3 id="前言">前言</h3>
<p>虽然，axios 是个优秀的 HTTP 库，但是，直接在项目中使用并不是那么方便，所以，我们需要对其进行一定程度上的配置封装，减少重复代码，方便调用。</p>
]]></summary>
        <content type="html"><![CDATA[<h3 id="前言">前言</h3>
<p>虽然，axios 是个优秀的 HTTP 库，但是，直接在项目中使用并不是那么方便，所以，我们需要对其进行一定程度上的配置封装，减少重复代码，方便调用。</p>
<!--more-->
<h3 id="开始">开始</h3>
<p>其实，网上关于 axios 封装的代码不少，但是大部分都是在入口文件（main.js）中进行 axios 全局对象属性定义的形式进行配置，类似于如下代码：</p>
<pre><code>axios.defaults.timeout = 10000

</code></pre>
<p>该方案有两个不足，首先，axios 封装代码耦合进入入口文件，不方便后期维护；其次，使用 axios 全局对象属性定义的方式进行配置，代码过于零散。</p>
<p>针对问题一，我使用了 Vue 源码结构中的一大核心思想——将功能拆分为文件，方便后期的维护。单独创建一个 <code>http.js</code> 或者 <code>http.ts</code> 文件，在文件中引入 axios 并对其进行封装配置，最后将其导出并挂载到 Vue 的原型上即可。此时，每次修改 axios 配置，只需要修改对应的文件即可，不会影响到不相关的功能。</p>
<p>针对问题二，采用 axios 官方推荐的，通过配置项创建 axios 实例的方式进行配置封装。</p>
<p>代码如下：</p>
<pre><code>// http.js
import axios from 'axios'
// 创建 axios 实例
const service = axios.create({
  // 配置项
})

</code></pre>
<h3 id="根据环境设置-baseurl">根据环境设置 baseURL</h3>
<p>baseURL 属性是请求地址前缀，将自动加在 url 前面，除非 url 是个绝对地址。正常情况下，在开发环境下和生产模式下有着不同的 baseURL，所以，我们需要根据不同的环境切换不同的 baseURL。</p>
<p>在开发模式下，由于有着 devServer 的存在，需要根据固定的 url 前缀进行请求地址重写，所以，在开发环境下，将 baseURL 设为某个固定的值，比如：<code>/apis</code>。</p>
<p>在生产模式下，根据 Java 模块的请求前缀的不同，可以设置不同的 baseURL。</p>
<p>具体代码如下：</p>
<pre><code>// 根据 process.env.NODE_ENV 区分状态，切换不同的 baseURL
const service = axios.create({
	baseURL: process.env.NODE_ENV === 'production' ? `/java` : '/apis',
})

</code></pre>
<h3 id="统一设置请求头">统一设置请求头</h3>
<p>在这里和大家聊一个问题，什么是封装？在我看来，封装是通过更少的调用代码覆盖更多的调用场景。</p>
<p>由于，大部分情况下，请求头都是固定的，只有少部分情况下，会需要一些特殊的请求头，所以，在这里，我采用的方案是，将普适性的请求头作为基础配置。当需要特殊请求头时，将特殊请求头作为参数传入，覆盖基础配置。</p>
<p>代码如下：</p>
<pre><code>const service = axios.create({
    ...
	headers: {
        get: {
          'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8'
          // 在开发中，一般还需要单点登录或者其他功能的通用请求头，可以一并配置进来
        },
        post: {
          'Content-Type': 'application/json;charset=utf-8'
          // 在开发中，一般还需要单点登录或者其他功能的通用请求头，可以一并配置进来
        }
  },
})

</code></pre>
<h3 id="跨域-超时-响应码处理">跨域、超时、响应码处理</h3>
<p>axios 中，提供是否允许跨域的属性——withCredentials，以及配置超时时间的属性——timeout，通过这两个属性，可以轻松处理跨域和超时的问题。</p>
<p>下面，我们来说说响应码处理：</p>
<p>axios 提供了 validateStatus 属性，用于定义对于给定的 HTTP 响应状态码是 resolve 或 reject promise。所以，正常设置的情况下，我们会将状态码为 2 系列或者 304 的请求设为 resolve 状态，其余为 reject 状态。结果就是，我们可以在业务代码里，使用 catch 统一捕获响应错误的请求，从而进行统一处理。</p>
<p>但是，由于我在代码里面使用了 async-await，而众所周知，async-await 捕获 catch 的方式极为麻烦，所以，在此处，我选择将所有响应都设为 resolve 状态，统一在 then 处理。</p>
<p>此部分代码如下：</p>
<pre><code>const service = axios.create({
	// 跨域请求时是否需要使用凭证
	withCredentials: true,
    // 请求 30s 超时
	timeout: 30000,
	validateStatus: function () {
		// 使用async-await，处理reject情况较为繁琐，所以全部返回resolve，在业务代码中处理异常
		return true
	},
})

</code></pre>
<h3 id="请求-响应处理">请求、响应处理</h3>
<p>在不使用 axios 的情况下，每次请求或者接受响应，都需要将请求或者响应序列化。</p>
<p>而在 axios 中， <code>transformRequest</code> 允许在向服务器发送请求前，修改请求数据；<code>transformResponse</code> 在传递给 then/catch 前，允许修改响应数据。</p>
<p>通过这两个钩子，可以省去大量重复的序列化代码。</p>
<p>代码如下：</p>
<pre><code>const service = axios.create({
    // 在向服务器发送请求前，序列化请求数据
    transformRequest: [function (data) {
        data = JSON.stringify(data)
        return data
    }],
    // 在传递给 then/catch 前，修改响应数据
    transformResponse: [function (data) {
        if (typeof data === 'string' &amp;&amp; data.startsWith('{')) {
            data = JSON.parse(data)
        }
        return data
    }]
})

</code></pre>
<h3 id="拦截器">拦截器</h3>
<p>拦截器，分为请求拦截器以及响应拦截器，分别在请求或响应被 then 或 catch 处理前拦截它们。</p>
<p>之前提到过，由于 async-await 中 catch 难以处理的问题，所以将出错的情况也作为 resolve 状态进行处理。但这带来了一个问题，请求或响应出错的情况下，结果没有数据协议中定义的 msg 字段（消息）。所以，我们需要在出错的时候，手动生成一个符合返回格式的返回数据。</p>
<p>由于，在业务中，没有需要在请求拦截器中做额外处理的需求，所以，请求拦截器的 resolve 状态，只需直接返回就可以了。</p>
<p>请求拦截器代码如下：</p>
<pre><code>// 请求拦截器
service.interceptors.request.use((config) =&gt; {
	return config
}, (error) =&gt; {
	// 错误抛到业务代码
    error.data = {}
    error.data.msg = '服务器异常，请联系管理员！'
    return Promise.resolve(error)
})

</code></pre>
<p>再来聊聊响应拦截器，还是之前的那个问题，除了请求或响应错误，还有一种情况也会导致返回的消息体不符合协议规范，那就是状态码不为 2 系列或 304 时。此时，我们还是需要做一样的处理——手动生成一个符合返回格式的返回数据。但是，有一点不一样，我们还需要根据不同的状态码生成不同的提示信息，以方便处理上线后的问题。</p>
<p>响应拦截器代码如下：</p>
<pre><code>// 根据不同的状态码，生成不同的提示信息
const showStatus = (status) =&gt; {
    let message = ''
    // 这一坨代码可以使用策略模式进行优化
    switch (status) {
        case 400:
            message = '请求错误(400)'
            break
        case 401:
            message = '未授权，请重新登录(401)'
            break
        case 403:
            message = '拒绝访问(403)'
            break
        case 404:
            message = '请求出错(404)'
            break
        case 408:
            message = '请求超时(408)'
            break
        case 500:
            message = '服务器错误(500)'
            break
        case 501:
            message = '服务未实现(501)'
            break
        case 502:
            message = '网络错误(502)'
            break
        case 503:
            message = '服务不可用(503)'
            break
        case 504:
            message = '网络超时(504)'
            break
        case 505:
            message = 'HTTP版本不受支持(505)'
            break
        default:
            message = `连接出错(${status})!`
    }
    return `${message}，请检查网络或联系管理员！`
}

// 响应拦截器
service.interceptors.response.use((response) =&gt; {
    const status = response.status
    let msg = ''
    if (status &lt; 200 || status &gt;= 300) {
        // 处理http错误，抛到业务代码
        msg = showStatus(status)
        if (typeof response.data === 'string') {
            response.data = { msg }
        } else {
            response.data.msg = msg
        }
    }
    return response
}, (error) =&gt; {
    // 错误抛到业务代码
    error.data = {}
    error.data.msg = '请求超时或服务器异常，请检查网络或联系管理员！'
    return Promise.resolve(error)
})

</code></pre>
<p><em>tips1：友情提示，上面那一坨 switch-case 代码，可以使用策略模式进行优化~</em></p>
<p><em>tips2：如果有一些业务相关的需求，可以加在拦截器中，比如：loading、鉴权等~</em></p>
<h3 id="支持-typescript">支持 TypeScript</h3>
<p>由于前段时间，我在部门内推了 TypeScript，为了满足自己的强迫症，将所有 js 文件改写为了 ts 文件。由于 axios 本身有 TypeScript 相关的支持，所以只需要把对应的类型导入，然后赋值即可。</p>
<h3 id="完整代码">完整代码</h3>
<pre><code>// http.ts
import axios, { AxiosRequestConfig, AxiosResponse } from 'axios'

const showStatus = (status: number) =&gt; {
  let message = ''
  switch (status) {
    case 400:
      message = '请求错误(400)'
      break
    case 401:
      message = '未授权，请重新登录(401)'
      break
    case 403:
      message = '拒绝访问(403)'
      break
    case 404:
      message = '请求出错(404)'
      break
    case 408:
      message = '请求超时(408)'
      break
    case 500:
      message = '服务器错误(500)'
      break
    case 501:
      message = '服务未实现(501)'
      break
    case 502:
      message = '网络错误(502)'
      break
    case 503:
      message = '服务不可用(503)'
      break
    case 504:
      message = '网络超时(504)'
      break
    case 505:
      message = 'HTTP版本不受支持(505)'
      break
    default:
      message = `连接出错(${status})!`
  }
  return `${message}，请检查网络或联系管理员！`
}

const service = axios.create({
  // 联调
  baseURL: process.env.NODE_ENV === 'production' ? `/` : '/apis',
  headers: {
    get: {
      'Content-Type': 'application/x-www-form-urlencoded;charset=utf-8'
    },
    post: {
      'Content-Type': 'application/json;charset=utf-8'
    }
  },
  // 是否跨站点访问控制请求
  withCredentials: true,
  timeout: 30000,
  transformRequest: [(data) =&gt; {
    data = JSON.stringify(data)
    return data
  }],
  validateStatus () {
    // 使用async-await，处理reject情况较为繁琐，所以全部返回resolve，在业务代码中处理异常
    return true
  },
  transformResponse: [(data) =&gt; {
    if (typeof data === 'string' &amp;&amp; data.startsWith('{')) {
      data = JSON.parse(data)
    }
    return data
  }]
})

// 请求拦截器
service.interceptors.request.use((config: AxiosRequestConfig) =&gt; {
    return config
}, (error) =&gt; {
    // 错误抛到业务代码
    error.data = {}
    error.data.msg = '服务器异常，请联系管理员！'
    return Promise.resolve(error)
})

// 响应拦截器
service.interceptors.response.use((response: AxiosResponse) =&gt; {
    const status = response.status
    let msg = ''
    if (status &lt; 200 || status &gt;= 300) {
        // 处理http错误，抛到业务代码
        msg = showStatus(status)
        if (typeof response.data === 'string') {
            response.data = {msg}
        } else {
            response.data.msg = msg
        }
    }
    return response
}, (error) =&gt; {
    // 错误抛到业务代码
    error.data = {}
    error.data.msg = '请求超时或服务器异常，请检查网络或联系管理员！'
    return Promise.resolve(error)
})

export default service

</code></pre>
]]></content>
    </entry>
</feed>